{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"outputs":[],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-05T02:15:44.37599Z","iopub.execute_input":"2021-08-05T02:15:44.376681Z","iopub.status.idle":"2021-08-05T02:15:44.394359Z","shell.execute_reply.started":"2021-08-05T02:15:44.376589Z","shell.execute_reply":"2021-08-05T02:15:44.393151Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["! pip install pmdarima"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-05T02:15:44.396313Z","iopub.execute_input":"2021-08-05T02:15:44.396807Z","iopub.status.idle":"2021-08-05T02:15:54.571724Z","shell.execute_reply.started":"2021-08-05T02:15:44.396749Z","shell.execute_reply":"2021-08-05T02:15:54.570562Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import pandas as pd\n","\n","\n","class DataProcessor:\n","    \"\"\"\n","    This class contains methods that will process data for both univariate\n","    and multivariate series.\n","    Parameters\n","    ----------\n","    conf_file: dict, optional=None\n","        Filepath to the json dictionary containing the execution parameters\n","    geo: string, optional=None\n","        Name of the geo selected\n","    can_drop_covid_data: bool, optional=None\n","        Determines whether covid_data should be dropped or not\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.train, self.test, self.submission = self._read_data()\n","        self._convert_to_datetime()\n","\n","    def _read_data(self):\n","        train = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")\n","        test = pd.read_csv(\"../input/covid19-global-forecasting-week-4/test.csv\")\n","        submission = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\n","        return train, test, submission\n","\n","    def _convert_to_datetime(self):\n","        \"\"\"\n","        Gets the DataFrame with all the time series and converts its dates to datetime\n","        and groups it by country and by province.\n","        \"\"\"\n","        self.train[\"Date\"] = pd.to_datetime(self.train[\"Date\"])\n","        self.test[\"Date\"] = pd.to_datetime(self.test[\"Date\"])\n","        return\n","\n","    def group(self, dataset, by):\n","        return dataset.groupby(by).sum()\n","    \n","    def run_pipeline(self, start_train_date, end_train_date):\n","        y_train = self._make_train_set(self.train, start_train_date, end_train_date)\n","        y_train = y_train.fillna(\"None\")\n","        y_train[\"Geo_id\"] = y_train.Country_Region + \"_\" + y_train.Province_State\n","        y_train = y_train.set_index(\"Geo_id\")\n","        y_train.drop([\"Country_Region\", \"Province_State\"], axis=1, inplace=True)\n","        y_test = self._make_test_set(self.test, end_train_date)\n","        y_test = y_test.fillna(\"None\")\n","        y_test[\"Geo_id\"] = y_test.Country_Region + \"_\" + y_test.Province_State\n","        y_test = y_test.set_index(\"Geo_id\")\n","        y_test.drop([\"Country_Region\", \"Province_State\"], axis=1, inplace=True)\n","        return y_train, y_test\n","    \n","    def _make_train_set(self, dataset, start_train_date, end_train_date):\n","        \"\"\"\n","        Makes the train set based on the\n","        dates.\n","        Parameters\n","        ----------\n","        dataset: pd.DataFrame\n","            Dataframe with the time series to be split\n","        start_train_date: datetime64 [ns]\n","            Start date of the training set\n","        end_train_date: datetime64 [ns]\n","            End date of the training set\n","        Returns\n","        -------\n","        y_train: pd.DataFrame\n","            Dataframe with the train set\n","        \"\"\"\n","        train_mask = (dataset['Date'] > start_train_date) & (dataset['Date'] <= end_train_date)\n","        y_train = dataset.loc[train_mask]\n","        y_train = y_train.reset_index(drop=True)\n","        y_train = y_train.drop(\"Id\", axis=1)\n","        return y_train\n","\n","    def _make_test_set(self, dataset, end_train_date):\n","        \"\"\"\n","        Makes the test set based on the\n","        dates.\n","        Parameters\n","        ----------\n","        dataset: pd.DataFrame\n","            Dataframe with the time series to be split\n","        start_train_date: datetime64 [ns]\n","            Start date of the training set\n","        end_train_date: datetime64 [ns]\n","            End date of the training set\n","        Returns\n","        -------\n","        y_test: pd.DataFrame\n","            Dataframe with the test set\n","        \"\"\"\n","        test_mask = dataset[\"Date\"] > end_train_date\n","        y_test = dataset.loc[test_mask]\n","        return y_test\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-05T02:15:54.577149Z","iopub.execute_input":"2021-08-05T02:15:54.577496Z","iopub.status.idle":"2021-08-05T02:15:54.697594Z","shell.execute_reply.started":"2021-08-05T02:15:54.577459Z","shell.execute_reply":"2021-08-05T02:15:54.696771Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["from statsmodels.tsa.arima.model import ARIMA\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.tsa.statespace.varmax import VARMAX\n","from statsmodels.tsa.statespace.dynamic_factor import DynamicFactor\n","from statsmodels.tsa.holtwinters import ExponentialSmoothing\n","from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n","from statsmodels.tsa.forecasting.stl import STLForecast\n","from statsmodels.tsa.statespace.dynamic_factor_mq import DynamicFactorMQ\n","from statsmodels.tsa.api import VAR\n","\n","\n","class Model:\n","    \"\"\"\n","    This class wraps the initialization, fit and forecast with the\n","    user-specified model of the statsmodels library\n","    Parameters\n","    ----------\n","    model_name: str\n","        Supports {\"VAR\", \"VARMAX\", \"SARIMAX\", \"DFM\", \"DFMMQ\",\n","                  \"ExponentialSmoothing\", \"ETSModel\", \"STLF\",\n","                  \"AUTO_ARIMA\", \"AUTO_SARIMAX\"}\n","        AUTO_SARIMAX is a model that uses auto arima to find the best order\n","        and seasonal order through auto arima but fits a sarimax model to\n","        the dataset.\n","    parameters: dict[str]\n","        Initialization parameters that depend on the model.\n","        Ex for VARMAX:\n","            parameters = {\"init_parameters\": {\"endog\": self.y_train,\n","                                              \"exog\": self.X_train}}\n","    \"\"\"\n","    def __init__(self, model_name, parameters):\n","        _models_dict = {\n","            \"VAR\": VAR,\n","            \"VARMAX\": VARMAX,\n","            \"SARIMAX\": SARIMAX,\n","            \"ARIMA\": ARIMA,\n","            \"DFM\": DynamicFactor,\n","            \"DFMMQ\": DynamicFactorMQ,\n","            \"ExponentialSmoothing\": ExponentialSmoothing,\n","            \"ETSModel\": ETSModel,\n","            \"STLF\": STLForecast\n","        }\n","        self.model_name = model_name\n","        if model_name == \"STLF\":\n","            if parameters[\"model\"] == \"ARIMA\":\n","                parameters[\"model\"] = ARIMA\n","            elif parameters[\"model\"] == \"ExponentialSmoothing\":\n","                parameters[\"model\"] = ExponentialSmoothing\n","        self.model = _models_dict[self.model_name](**parameters)\n","\n","    def fit(self, parameters):\n","        \"\"\"\n","        Fits the model.\n","        The auto arima library is different, because it doesn't have an\n","        initialization method.\n","        Parameters\n","        ----------\n","        parameters: dict[str]\n","            Model-dependent-fit-parameters.\n","        \"\"\"\n","        if self.model_name == \"DynamicFactorMQ\":\n","            self.results = self.model.fit_em(**parameters)\n","        else:\n","            self.results = self.model.fit(**parameters)\n","        if self.model_name == \"STLF\":\n","            self.y_fitted = self.results.result\n","        else:\n","            self.y_fitted = self.results.fittedvalues\n","\n","    def forecast(self, parameters):\n","        \"\"\"\n","        Makes a forecast with the fitted model.\n","        Parameters\n","        ----------\n","        parameters: dict[str]\n","            Model-dependent-forecast-parameters.\n","        \"\"\"\n","        if (self.model_name == \"VAR\" or self.model_name == \"VARMAX\" or\n","                self.model_name == \"DFM\" or\n","                self.model_name == \"DFMMQ\" or\n","                self.model_name == \"SARIMAX\" or\n","                self.model_name == \"ARIMA\" or\n","                self.model_name == \"ExponentialSmoothing\" or\n","                self.model_name == \"ETSModel\" or\n","                self.model_name == \"STLF\"):\n","            self.y_hat = self.results.forecast(**parameters)\n","\n","    def get_info_criteria(self, ic):\n","        return self.results.info_criteria(ic)\n","\n","    def get_var_order(self):\n","        if self.model_name == \"VAR\":\n","            return self.results.k_ar"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-05T02:15:54.698924Z","iopub.execute_input":"2021-08-05T02:15:54.699353Z","iopub.status.idle":"2021-08-05T02:15:56.042645Z","shell.execute_reply.started":"2021-08-05T02:15:54.699321Z","shell.execute_reply":"2021-08-05T02:15:56.041593Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["class ModelParametersMaker:\n","    \"\"\"\n","        Maps model parameters into class dictionaries.\n","        Parameters\n","        ----------\n","        y_train: pd.DataFrame()\n","            DataFrame containing the train set.\n","        num_forecast_observations: int\n","            Defines number of forecast observations.\n","        X_train, X_test: pd.DataFrame\n","            Exogenous variables dataframes\n","    \"\"\"\n","\n","    def __init__(self, num_forecast_observations, model_name, y_train,\n","                 parameters, X_train=None, X_test=None):\n","        self.num_forecast_observations = num_forecast_observations\n","        self.y_train = y_train\n","        self.X_train = X_train\n","        self.X_test = X_test\n","        if model_name == \"VAR\":\n","            self.make_var_parameters(**parameters)\n","        elif model_name == \"VARMAX\":\n","            self.make_varmax_parameters(**parameters)\n","        elif model_name == \"DFM\":\n","            self.make_dfm_parameters(**parameters)\n","        elif model_name == \"DFMMQ\":\n","            self.make_dfm_mq_parameters(**parameters)\n","        elif model_name == \"SARIMAX\":\n","            self.make_sarimax_parameters(**parameters)\n","        elif model_name == \"ARIMA\":\n","            self.make_arima_parameters(**parameters)\n","        elif model_name == \"ExponentialSmoothing\":\n","            self.make_exponential_smoothing_parameters(**parameters)\n","        elif model_name == \"ETSModel\":\n","            self.make_ets_model_parameters(**parameters)\n","        elif model_name == \"STLF\":\n","            self.make_stlf_parameters(**parameters)\n","        elif model_name == \"AUTO_ARIMA\":\n","            self.make_auto_arima_parameters(**parameters)\n","        elif model_name == \"AUTO_SARIMAX\":\n","            self.make_auto_sarimax_parameters(**parameters)\n","        else:\n","            print(\"Model doesn't exist.\")\n","\n","    def make_var_parameters(self, maxlags, ic=\"aic\", trend=\"c\"):\n","        self.parameters = {\n","            \"init_parameters\": {\"endog\": self.y_train,\n","                                \"exog\": self.X_train},\n","            \"fit_parameters\": {\"maxlags\": maxlags,\n","                               \"ic\": ic,\n","                               \"trend\": trend},\n","            \"forecast_parameters\": {\"y\": self.y_train.values,\n","                                    \"steps\": self.num_forecast_observations,\n","                                    \"exog_future\": self.X_test}\n","        }\n","\n","    def make_varmax_parameters(self, order, trend=\"c\", measurement_error=False,\n","                               ic=\"aic\"):\n","        self.parameters = {\n","            \"init_parameters\": {\"endog\": self.y_train,\n","                                \"exog\": self.X_train,\n","                                \"order\": order,\n","                                \"trend\": trend,\n","                                \"measurement_error\": measurement_error},\n","            \"fit_parameters\": {\"ic\": ic},\n","            \"forecast_parameters\": {\"y\": self.y_train.values,\n","                                    \"steps\": self.num_forecast_observations,\n","                                    \"exog\": self.X_test}\n","        }\n","\n","    def make_dfm_parameters(self, k_factors, factor_order,\n","                            error_order):\n","        self.parameters = {\n","            \"init_parameters\": {\"endog\": self.y_train,\n","                                \"exog\": self.X_train,\n","                                \"k_factors\": k_factors,\n","                                \"factor_order\": factor_order,\n","                                \"error_order\": error_order},\n","            \"fit_parameters\": {},\n","            \"forecast_parameters\": {\"steps\": self.num_forecast_observations,\n","                                    \"exog\": self.X_test}\n","        }\n","\n","    def make_dfm_mq_parameters(self, factors, factor_orders,\n","                               factor_multiplicities, standardize):\n","        self.parameters = {\n","            \"init_parameters\": {\"endog\": self.y_train,\n","                                \"k_endog_monthly\": None,\n","                                \"factors\": factors,\n","                                \"factor_orders\": factor_orders,\n","                                \"factor_multiplicities\": factor_multiplicities,\n","                                \"idiosyncratic_ar1\": True,\n","                                \"standardize\": standardize,\n","                                \"endog_quarterly\": None,\n","                                \"init_t0\": False,\n","                                \"obs_cov_diag\": False},\n","            \"fit_parameters\": {},\n","            \"forecast_parameters\": {\"steps\": self.num_forecast_observations}\n","        }\n","\n","    def make_sarimax_parameters(self, order, seasonal_order):\n","        self.parameters = {\n","            \"init_parameters\": {\"endog\": self.y_train,\n","                                \"order\": order,\n","                                \"seasonal_order\": seasonal_order,\n","                                \"enforce_stationarity\": False,\n","                                \"enforce_invertibility\": False},\n","            \"fit_parameters\": {},\n","            \"forecast_parameters\": {\"steps\": self.num_forecast_observations}\n","        }\n","\n","    def make_arima_parameters(self, order):\n","        self.parameters = {\n","            \"init_parameters\": {\"endog\": self.y_train,\n","                                \"order\": order,\n","                                \"enforce_stationarity\": False,\n","                                \"enforce_invertibility\": False},\n","            \"fit_parameters\": {},\n","            \"forecast_parameters\": {\"steps\": self.num_forecast_observations}\n","        }\n","\n","    def make_exponential_smoothing_parameters(self, trend, damped, seasonal,\n","                                              seasonal_periods, use_boxcox,\n","                                              remove_bias):\n","        self.parameters = {\n","            \"init_parameters\": {\n","                \"endog\": self.y_train,\n","                \"trend\": trend,\n","                \"damped\": damped,\n","                \"seasonal\": seasonal,\n","                \"seasonal_periods\": seasonal_periods\n","            },\n","            \"fit_parameters\": {\n","                \"optimized\": True,\n","                \"use_boxcox\": use_boxcox,\n","                \"remove_bias\": remove_bias\n","            },\n","            \"forecast_parameters\": {\"steps\": self.num_forecast_observations}\n","        }\n","\n","    def make_ets_model_parameters(self, error, trend, damped_trend, seasonal,\n","                                  seasonal_periods):\n","        self.parameters = {\n","            \"init_parameters\": {\n","                \"endog\": self.y_train.values.flatten(),\n","                \"error\": error,\n","                \"trend\": trend,\n","                \"damped_trend\": damped_trend,\n","                \"seasonal\": seasonal,\n","                \"seasonal_periods\": seasonal_periods,\n","                \"freq\": \"MS\",\n","                \"dates\": self.y_train.index\n","            },\n","            \"fit_parameters\": {},\n","            \"forecast_parameters\": {\"steps\": self.num_forecast_observations}\n","        }\n","\n","    def make_stlf_parameters(self, model, model_kwargs, robust):\n","        self.parameters = {\n","            \"init_parameters\": {\n","                \"endog\": self.y_train,\n","                \"model\": model,\n","                \"model_kwargs\": model_kwargs,\n","                \"robust\": robust\n","            },\n","            \"fit_parameters\": {},\n","            \"forecast_parameters\": {\"steps\": self.num_forecast_observations}\n","        }\n","\n","    def make_auto_arima_parameters(self, start_p, start_q, max_p, max_d,\n","                                   max_q, start_P, start_Q, max_P, D,\n","                                   max_Q, m, max_order, trend, stepwise, include_D):\n","        self.parameters = {\n","            \"init_parameters\": {},\n","            \"fit_parameters\": {\"y\": self.y_train,\n","                               \"start_p\": start_p,\n","                               \"start_q\": start_q,\n","                               \"max_p\": max_p,\n","                               \"max_d\": max_d,\n","                               \"max_q\": max_q,\n","                               \"start_P\": start_P,\n","                               \"start_Q\": start_Q,\n","                               \"max_P\": max_P,\n","                               \"D\": D,\n","                               \"max_Q\": max_Q,\n","                               \"m\": m,\n","                               \"max_order\": max_order,\n","                               \"trend\": trend,\n","                               \"stepwise\": stepwise,\n","                               \"include_D\": include_D},\n","            \"forecast_parameters\": {\"steps\": self.num_forecast_observations}\n","        }\n","\n","    def make_auto_sarimax_parameters(self, parameters):\n","        parameters[\"y\"] = self.y_train\n","        self.parameters = {\n","            \"init_parameters\": {},\n","            \"fit_parameters\": parameters,\n","            \"forecast_parameters\": {\"steps\": self.num_forecast_observations}\n","        }"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-05T02:15:56.044225Z","iopub.execute_input":"2021-08-05T02:15:56.044572Z","iopub.status.idle":"2021-08-05T02:15:56.074815Z","shell.execute_reply.started":"2021-08-05T02:15:56.04454Z","shell.execute_reply":"2021-08-05T02:15:56.07398Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\n","from sklearn.metrics import mean_squared_log_error\n","from sklearn.model_selection import TimeSeriesSplit\n","from pmdarima.arima import auto_arima\n","\n","\n","INIT_PARAMETERS = \"init_parameters\"\n","FIT_PARAMETERS = \"fit_parameters\"\n","FORECAST_PARAMETERS = \"forecast_parameters\"\n","\n","\n","class CVOptimizer:\n","    \"\"\"\n","    Implements Cross Validation for Time Series wrapping the\n","    sklearn.model_selection.TimeSeriesSplit method. The cross\n","    validation score is computed by the mean of the rmse of each fold.\n","    Parameters\n","    ----------\n","    model_name: str\n","        Check _model_dict attribute from model.py for the\n","        acceptable model_names. Example: 'VAR'\n","    y_train: pd.DataFrame\n","        Univariate or Multivariate Time Series\n","    country_name: str\n","        Country name\n","    test_fold_size: int\n","        Size of the test fold of the cross validation\n","    X_params: str, optional=None\n","        {\"STL\", \"seasonal_component_peak_values\"}\n","        Method through which exogenous variables are made.\n","    verbose: bool\n","        Whether or not to print debugging info\n","    cv: int\n","        Number of folds\n","    \"\"\"\n","    def __init__(self, model_name, train_set,\n","                 country_name, test_fold_size,\n","                 verbose=False, cv=3):\n","        self.model_name = model_name\n","        self.train_set = train_set\n","        self.country_name = country_name\n","        self.test_fold_size = test_fold_size\n","        self.verbose = verbose\n","        self.cv = cv\n","        \n","    def cross_val_score(self, param_combination):\n","        \"\"\"\n","        Calculates the cross validation score for the given number of folds.\n","        Saves the score of each fold and the parameters in a tuple\n","        model_scores (score, param_combination), where score is computed\n","        by the mean of the rmse of each fold.\n","        Parameters\n","        ----------\n","        param_combination: dict\n","            Keys: parameter names of the model\n","            Values: value of the parameters\n","            Example:\n","                \"param_combination\" = {\n","                    \"maxlags\": maxlags,\n","                    \"trend\": trend\n","                }\n","        Exception\n","        ---------\n","        If the model can't fit any of the folds, it will be discarded.\n","        \"\"\"\n","        tscv = TimeSeriesSplit(n_splits=self.cv)\n","        k_fold = 1\n","        model_rmsle = []\n","        for train_index, test_index in tscv.split(self.train_set):\n","            if self.verbose:\n","                print(f\"Training fold number {k_fold}\")\n","\n","            y_train, y_test = self._make_sets(\n","                train_index, test_index\n","            )\n","            if self.model_name == \"AUTO_ARIMA\":\n","                try:\n","                    num_forecast_observations = self.test_fold_size\n","                    model_parameters_maker = ModelParametersMaker(\n","                        num_forecast_observations, self.model_name, y_train,\n","                        param_combination\n","                    )\n","                    parameters = model_parameters_maker.parameters\n","                    model = auto_arima(**parameters[FIT_PARAMETERS])\n","                    forecast = model.predict(**parameters[FORECAST_PARAMETERS])\n","                    model_rmsle.append(self._measure_rmsle(forecast, y_test))\n","                    print(\"Success\")\n","                except Exception as e:\n","                    if self.verbose:\n","                        print(f\"Error for series {self.country_name}\")\n","                        print(e)\n","                        import traceback\n","                        traceback.print_exc()\n","                    model_rmsle.append(np.inf)\n","                finally:\n","                    k_fold += 1\n","            else:              \n","                try:\n","                    num_forecast_observations = self.test_fold_size\n","                    model_parameters_maker = ModelParametersMaker(\n","                        num_forecast_observations, self.model_name, y_train,\n","                        param_combination\n","                    )\n","                    model = self._run_model_pipeline(model_parameters_maker.parameters)\n","                    model_rmsle.append(self._measure_rmsle(model.y_hat, y_test))\n","                    print(\"Success\")\n","                except Exception as e:\n","                    if self.verbose:\n","                        print(f\"Error for series {self.country_name}\")\n","                        print(e)\n","                        import traceback\n","                        traceback.print_exc()\n","                    model_rmsle.append(np.inf)\n","                finally:\n","                    k_fold += 1\n","        model_rmsle = self._handle_inf_scores(model_rmsle)\n","        mean_score = np.mean(model_rmsle)\n","        self.model_scores = (mean_score, param_combination)      \n","\n","    def _make_sets(self, train_index, test_index):\n","        train_index_ = np.concatenate(\n","            (train_index, test_index[:-self.test_fold_size]),\n","            axis=None\n","        )\n","        test_index_ = test_index[-self.test_fold_size:]\n","        y_train = self.train_set.iloc[train_index_]\n","        y_test = self.train_set.iloc[test_index_]\n","        return y_train, y_test\n","\n","\n","    def _run_model_pipeline(self, model_parameters):\n","        \"\"\"\n","        Runs the model pipeline: initialization, fitting, forecast\n","        Parameters\n","        ----------\n","        model_parameters: dict[str : str]\n","            Keys: {\"init_parameters\", \"fit_parameters\", \"forecast_parameters\"}\n","            Values: depend on the model\n","        Returns\n","            Model after running pipeline\n","        \"\"\"\n","        model = Model(\n","            self.model_name, model_parameters[INIT_PARAMETERS]\n","        )\n","        model.fit(model_parameters[FIT_PARAMETERS])\n","        model.forecast(model_parameters[FORECAST_PARAMETERS])\n","        return model\n","    \n","    def _measure_rmsle(self, actual, predicted):\n","        \"\"\"\n","        Computes the rmse between the actual and the predicted values.\n","        Parameters\n","        ----------\n","        actual : pd.DataFrame\n","            DataFrame containing the observed values\n","        predicted : pd.DataFrame\n","            DataFrame containing the predicted values\n","        Returns\n","        -------\n","            rmse between the actual and predicted values\n","        \"\"\"\n","        return np.sqrt(mean_squared_log_error(actual, predicted))\n","\n","    def _handle_inf_scores(self, model_rmsle):\n","        np_array = np.array(model_rmsle)\n","        inf_mask = ~np.isfinite(np_array)\n","        # Penalizes models that scored inf. It will double\n","        # the last fold's score and attribute it to the\n","        # folds that scored infinite\n","        np_array[inf_mask] = np_array[self.cv-1] * 2\n","        return list(np_array)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-05T02:15:56.075956Z","iopub.execute_input":"2021-08-05T02:15:56.076384Z","iopub.status.idle":"2021-08-05T02:15:56.699834Z","shell.execute_reply.started":"2021-08-05T02:15:56.076354Z","shell.execute_reply":"2021-08-05T02:15:56.69905Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import warnings\n","\n","import numpy as np\n","import pandas as pd\n","from pmdarima.arima import auto_arima\n","\n","\n","INIT_PARAMETERS = \"init_parameters\"\n","FIT_PARAMETERS = \"fit_parameters\"\n","FORECAST_PARAMETERS = \"forecast_parameters\"\n","\n","\n","def get_exp_param_combinations():\n","    trend = [\"add\", \"mul\", None]\n","    damped = [True, False]\n","    seasonal = [\"add\", \"mul\", None]\n","    seasonal_periods = [30]\n","    use_boxcox = [True, False]\n","    remove_bias = [True, False]\n","\n","    param_combinations = []\n","    for t in trend:\n","        for d in damped:\n","            for s in seasonal:\n","                for sp in seasonal_periods:\n","                    for u in use_boxcox:\n","                        for r in remove_bias:\n","                            param_combination = {}\n","                            param_combination[\"trend\"] = t\n","                            param_combination[\"damped\"] = d\n","                            param_combination[\"seasonal\"] = s\n","                            param_combination[\"seasonal_periods\"] = sp\n","                            param_combination[\"use_boxcox\"] = u\n","                            param_combination[\"remove_bias\"] = r\n","                            param_combinations.append(param_combination)\n","    return param_combinations\n","\n","\n","def get_auto_param_combinations():\n","    parameters = {}\n","    parameters[\"start_p\"] = 0\n","    parameters[\"start_q\"] = 0\n","    parameters[\"max_p\"] = 5\n","    parameters[\"max_d\"] = 2\n","    parameters[\"max_q\"] = 5\n","    parameters[\"start_P\"] = 0\n","    parameters[\"start_Q\"] = 0\n","    parameters[\"max_P\"] = 5\n","    parameters[\"D\"] = 1\n","    parameters[\"max_Q\"] = 5\n","    parameters[\"m\"] = 30\n","    parameters[\"max_order\"] = 12\n","    parameters[\"trend\"] = \"t\"\n","    parameters[\"stepwise\"] = True\n","    # include_D: whether or not to force a seasonal differentiation\n","    parameters[\"include_D\"] = False\n","\n","    param_combinations = []\n","    param_combinations.append(parameters)\n","    return param_combinations\n","\n","\n","\n","def optimize(model_name, y_train, param_combinations, geo, test_fold_size, verbose=False, cv=3):\n","    cv_scores = []\n","    for param_combination in param_combinations:\n","        cv_optimizer = CVOptimizer(\n","            model_name, y_train, geo, test_fold_size, verbose=verbose, cv=cv\n","        )\n","        cv_optimizer.cross_val_score(param_combination)\n","        cv_scores.append(cv_optimizer.model_scores)\n","    cv_scores.sort(key=lambda x: x[0])\n","    return cv_scores\n","\n","\n","def best_exp_model_forecast(exp_model_name, best_exp_score,\n","                            num_forecast_observations, y_train):\n","    model_parameters_maker = ModelParametersMaker(\n","        num_forecast_observations, exp_model_name, y_train,\n","        best_exp_score[1]\n","    )\n","    model_parameters = model_parameters_maker.parameters\n","    model = Model(\n","        exp_model_name, model_parameters[INIT_PARAMETERS]\n","    )\n","    model.fit(model_parameters[FIT_PARAMETERS])\n","    model.forecast(model_parameters[FORECAST_PARAMETERS])\n","    return model.y_hat\n","\n","\n","def best_auto_model_forecast(auto_model_name, best_auto_score,\n","                             num_forecast_observations, y_train):\n","    model_parameters_maker = ModelParametersMaker(\n","        num_forecast_observations, auto_model_name, y_train,\n","        best_auto_score[1]\n","    )\n","    model_parameters = model_parameters_maker.parameters\n","    model = auto_arima(**model_parameters[FIT_PARAMETERS])\n","    forecast = model.predict(n_periods=num_forecast_observations)\n","    return forecast\n","\n","def run_pipeline(y_train, geo, test_fold_size, num_forecast_observations):\n","    exp_model_name = \"ExponentialSmoothing\"\n","    exp_param_combinations = get_exp_param_combinations()\n","    exp_scores = optimize(\n","        exp_model_name, y_train, exp_param_combinations, geo,\n","        test_fold_size, verbose=False, cv=3\n","    )\n","    best_exp_score = exp_scores[0]\n","    y_hat_exp = best_exp_model_forecast(\n","        exp_model_name, best_exp_score, num_forecast_observations, y_train\n","    )\n","    if isinstance(y_hat_exp, pd.Series):\n","        y_hat_exp = y_hat_exp.values\n","    \n","    auto_model_name = \"AUTO_ARIMA\"\n","    auto_param_combinations = get_auto_param_combinations()\n","    try:\n","        auto_scores = optimize(\n","            auto_model_name, y_train, auto_param_combinations, geo,\n","            test_fold_size, verbose=False, cv=3\n","        )\n","        best_auto_score = auto_scores[0]\n","        y_hat_auto = best_auto_model_forecast(\n","            auto_model_name, best_auto_score, num_forecast_observations, y_train\n","        )\n","        if isinstance(y_hat_auto, pd.Series):\n","            y_hat_auto = y_hat_auto.values\n","        y_hat = y_hat_exp * 0.75 + y_hat_auto * 0.25\n","    except:\n","        best_auto_score = np.inf\n","        y_hat = y_hat_exp\n","    return y_hat\n","\n","\n","if __name__ == \"__main__\":\n","    \n","    data_processor = DataProcessor()\n","    START_TRAIN_DATE = pd.to_datetime(\"2020-01-22\")\n","    END_TRAIN_DATE = pd.to_datetime(\"2020-04-14\")\n","    train, test = data_processor.run_pipeline(START_TRAIN_DATE, END_TRAIN_DATE)\n","    unique_geos = train.index.unique()\n","    submission = data_processor.submission\n","\n","    for geo in unique_geos:\n","        y_train = train.loc[geo, :].copy()\n","        y_train.set_index(\"Date\", inplace=True)\n","        y_train_cc = y_train[\"ConfirmedCases\"]\n","        y_train_f = y_train[\"Fatalities\"]\n","        y_train_cc.clip(0, inplace=True)\n","        y_train_f.clip(0, inplace=True)\n","        y_test = test.loc[geo].copy()\n","        y_test.set_index(\"Date\", inplace=True)\n","        num_forecast_observations = len(y_test)\n","        test_fold_size = 10\n","\n","        y_hat_cc = run_pipeline(y_train_cc, geo, test_fold_size, num_forecast_observations)\n","        y_hat_f = run_pipeline(y_train_f, geo, test_fold_size, num_forecast_observations)\n","        submission.loc[submission[\"ForecastId\"].isin(y_test[\"ForecastId\"]), \"ConfirmedCases\"] = y_hat_cc\n","        submission.loc[submission[\"ForecastId\"].isin(y_test[\"ForecastId\"]), \"Fatalities\"] = y_hat_f\n","        print(f\"geo {geo}\")\n","        print(submission.loc[submission[\"ForecastId\"].isin(y_test[\"ForecastId\"]), \"Fatalities\"])\n","        print(submission.loc[submission[\"ForecastId\"].isin(y_test[\"ForecastId\"]), \"ConfirmedCases\"])\n","    submission.to_csv(\"submission.csv\", index=False)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-05T02:15:56.700936Z","iopub.execute_input":"2021-08-05T02:15:56.701343Z","iopub.status.idle":"2021-08-05T02:21:21.950062Z","shell.execute_reply.started":"2021-08-05T02:15:56.701314Z","shell.execute_reply":"2021-08-05T02:21:21.94661Z"},"trusted":true}}]}